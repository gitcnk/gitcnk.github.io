<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3 The Infamous ‘n &gt; 30 rule’ | Statistics: A Critical Look</title>
  <meta name="description" content="3 The Infamous ‘n &gt; 30 rule’ | Statistics: A Critical Look" />
  <meta name="generator" content="bookdown 0.18 and GitBook 2.6.7" />

  <meta property="og:title" content="3 The Infamous ‘n &gt; 30 rule’ | Statistics: A Critical Look" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3 The Infamous ‘n &gt; 30 rule’ | Statistics: A Critical Look" />
  
  
  

<meta name="author" content="CK" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="sampling-distributions.html"/>
<link rel="next" href="the-bootstrap-method.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="custom.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Statistics: A Critical Look</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="some-preliminary-questions.html"><a href="some-preliminary-questions.html"><i class="fa fa-check"></i><b>1</b> Some Preliminary Questions</a></li>
<li class="chapter" data-level="2" data-path="sampling-distributions.html"><a href="sampling-distributions.html"><i class="fa fa-check"></i><b>2</b> Sampling Distributions</a><ul>
<li class="chapter" data-level="2.1" data-path="sampling-distributions.html"><a href="sampling-distributions.html#how-to-construct-a-sampling-distribution"><i class="fa fa-check"></i><b>2.1</b> How to Construct a Sampling Distribution?</a></li>
<li class="chapter" data-level="2.2" data-path="sampling-distributions.html"><a href="sampling-distributions.html#some-questions-to-ponder"><i class="fa fa-check"></i><b>2.2</b> Some Questions to Ponder</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="the-infamous-n-30-rule.html"><a href="the-infamous-n-30-rule.html"><i class="fa fa-check"></i><b>3</b> The Infamous ‘n &gt; 30 rule’</a><ul>
<li class="chapter" data-level="3.1" data-path="the-infamous-n-30-rule.html"><a href="the-infamous-n-30-rule.html#central-limit-theorem"><i class="fa fa-check"></i><b>3.1</b> Central Limit Theorem</a></li>
<li class="chapter" data-level="3.2" data-path="the-infamous-n-30-rule.html"><a href="the-infamous-n-30-rule.html#explorations-with-real-data"><i class="fa fa-check"></i><b>3.2</b> Explorations with Real Data</a><ul>
<li class="chapter" data-level="" data-path="the-infamous-n-30-rule.html"><a href="the-infamous-n-30-rule.html#nba-player-salaries"><i class="fa fa-check"></i>NBA Player Salaries</a></li>
<li class="chapter" data-level="" data-path="the-infamous-n-30-rule.html"><a href="the-infamous-n-30-rule.html#undergraduates-in-us-colleges-and-universities"><i class="fa fa-check"></i>Undergraduates in US Colleges and Universities</a></li>
<li class="chapter" data-level="" data-path="the-infamous-n-30-rule.html"><a href="the-infamous-n-30-rule.html#departure-delays-in-laguardia-airport"><i class="fa fa-check"></i>Departure Delays in LaGuardia Airport</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="the-infamous-n-30-rule.html"><a href="the-infamous-n-30-rule.html#some-questions-to-ponder-1"><i class="fa fa-check"></i><b>3.3</b> Some Questions to Ponder</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="the-bootstrap-method.html"><a href="the-bootstrap-method.html"><i class="fa fa-check"></i><b>4</b> The Bootstrap Method</a><ul>
<li class="chapter" data-level="4.1" data-path="the-bootstrap-method.html"><a href="the-bootstrap-method.html#bootstrap-sampling-distribution"><i class="fa fa-check"></i><b>4.1</b> Bootstrap Sampling Distribution</a></li>
<li class="chapter" data-level="4.2" data-path="the-bootstrap-method.html"><a href="the-bootstrap-method.html#bootstrap-confidence-intervals"><i class="fa fa-check"></i><b>4.2</b> Bootstrap Confidence Intervals</a><ul>
<li class="chapter" data-level="" data-path="the-bootstrap-method.html"><a href="the-bootstrap-method.html#bootstrap-se-plug-in-method"><i class="fa fa-check"></i>Bootstrap SE Plug-in Method</a></li>
<li class="chapter" data-level="" data-path="the-bootstrap-method.html"><a href="the-bootstrap-method.html#bootstrap-percentile-method"><i class="fa fa-check"></i>Bootstrap Percentile Method</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="the-bootstrap-method.html"><a href="the-bootstrap-method.html#things-to-ponder"><i class="fa fa-check"></i><b>4.3</b> Things to Ponder</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="permutation-randomization-tests.html"><a href="permutation-randomization-tests.html"><i class="fa fa-check"></i><b>5</b> Permutation (Randomization) Tests</a><ul>
<li class="chapter" data-level="5.1" data-path="permutation-randomization-tests.html"><a href="permutation-randomization-tests.html#alternative-to-the-two-sample-t-test"><i class="fa fa-check"></i><b>5.1</b> Alternative to the Two Sample t-test</a></li>
<li class="chapter" data-level="5.2" data-path="permutation-randomization-tests.html"><a href="permutation-randomization-tests.html#application-to-categorical-data"><i class="fa fa-check"></i><b>5.2</b> Application to Categorical Data</a></li>
<li class="chapter" data-level="5.3" data-path="permutation-randomization-tests.html"><a href="permutation-randomization-tests.html#application-to-linear-regression"><i class="fa fa-check"></i><b>5.3</b> Application to Linear Regression</a><ul>
<li class="chapter" data-level="" data-path="permutation-randomization-tests.html"><a href="permutation-randomization-tests.html#summary"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="permutation-randomization-tests.html"><a href="permutation-randomization-tests.html#things-to-ponder-1"><i class="fa fa-check"></i><b>5.4</b> Things to ponder</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="p-values-jelly-beans-and-mosquitoes.html"><a href="p-values-jelly-beans-and-mosquitoes.html"><i class="fa fa-check"></i><b>6</b> P-values, Jelly-Beans, and Mosquitoes</a><ul>
<li class="chapter" data-level="6.1" data-path="p-values-jelly-beans-and-mosquitoes.html"><a href="p-values-jelly-beans-and-mosquitoes.html#what-is-a-p-value"><i class="fa fa-check"></i><b>6.1</b> What is a p-value?</a></li>
<li class="chapter" data-level="6.2" data-path="p-values-jelly-beans-and-mosquitoes.html"><a href="p-values-jelly-beans-and-mosquitoes.html#p-values-and-large-samples."><i class="fa fa-check"></i><b>6.2</b> P-values and Large Samples.</a></li>
<li class="chapter" data-level="6.3" data-path="p-values-jelly-beans-and-mosquitoes.html"><a href="p-values-jelly-beans-and-mosquitoes.html#slicing-and-dicing-the-data"><i class="fa fa-check"></i><b>6.3</b> Slicing and Dicing the Data</a></li>
<li class="chapter" data-level="" data-path="p-values-jelly-beans-and-mosquitoes.html"><a href="p-values-jelly-beans-and-mosquitoes.html#summary-1"><i class="fa fa-check"></i>Summary</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://www.hamilton.edu" target="blank">Hamilton College</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistics: A Critical Look</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="the-infamous-n-30-rule" class="section level1">
<h1><span class="header-section-number">3</span> The Infamous ‘n &gt; 30 rule’</h1>
<p>The title of this chapter may be a bit confusing. The formal title should be “The Central Limit Theorem”. But I wanted to make a point in this chapter about the misuses of this remarkable theorem. Let’s dive in.</p>
<div id="central-limit-theorem" class="section level2">
<h2><span class="header-section-number">3.1</span> Central Limit Theorem</h2>
<p>Before we formally introduce this theorem, let us first look at a motivating example. Recall the service time example we saw in Chapter 2. In that, we saw that the sampling distribution of <span class="math inline">\(\bar x\)</span> tend to follow a normal model as <span class="math inline">\(n\)</span> increases while the sampling distribution of the sample maximum does not show any normal behavior. To put things in perspective, let us look at some plots.</p>
<p><br />
</p>
<p><strong>Sampling Distributions of the Sample Mean</strong></p>
<p><img src="_main_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<p>Carefully examine the plots above. In particular, pay attention to the following:</p>
<ul>
<li>shape</li>
<li>spread (look at the scale of the x-axis)</li>
</ul>
<p>The behavior of the sample mean as <span class="math inline">\(n\)</span> increases has two noteworthy aspects.</p>
<ol style="list-style-type: decimal">
<li><p>For larger samples, like <span class="math inline">\(n &gt; 100\)</span>, the sampling distribution of <span class="math inline">\(\bar x\)</span> is normal with the “center” being very close to the true mean of the population that we sample from.</p></li>
<li><p>The spread get’s smaller as <span class="math inline">\(n\)</span> increases.</p></li>
</ol>
<p>Why is this important to us?</p>
<p>First, the normal distribution is something that is easy to understand and we know how to calculate probabilities using the normal model. Also, recall the “68-95-99.7% rule” which describes how the probabilities change with respect to the standard deviation (spread) of the model. So, anything that follows a normal model is good news for the statistician, because we know a LOT about this model.</p>
<p>Second, the spread (standard deviation) decreases as <span class="math inline">\(n\)</span> increases. This is encouraging because it ensures that for larger samples we are not too far off from the “center” of the distribution which happens to be very close to the true mean.</p>
<p>In fact, These facts were discovered a long time ago and they are summarized in one of the celebrated theorems in statistics. It is called the <strong>Central Limit Theorem</strong>. It says, under some conditions, the sample mean <span class="math inline">\(\bar x\)</span> follows a normal model with center being at the true population mean and the spread decreases at a rate of <span class="math inline">\(1/\sqrt n\)</span>. We can denote this more succinctly as follows:<br />
<span class="math display">\[ \bar x \sim N(\mu , \frac{\sigma}{\sqrt n})\]</span></p>
<p>We will explore this theorem further in this chapter. But, let us first look at an example ( a statistic) that do not agree with the Central Limit Theorem. This example helps us to understand the core idea of this theorem.</p>
<p>The plots below are sampling distributions of the sample maximum constructed from the same service time population (Example 2.1). Carefully look at the shape and spread of these plots.</p>
<p><br />
</p>
<p><strong>Sampling Distributions of the Sample Maximum</strong></p>
<p><img src="_main_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<p>You’ll notice immediately that the shape does not look normal even for <span class="math inline">\(n=300\)</span>. Also, the spread does not decrease that much. In fact, the spread is fairly constant across all 4 distributions. This is NOT an accident. The reason that this statistic, the sample maximum, does not obey the Central Limit Theorem is because it is NOT an average constructed from the sample. This is the core idea of this theorem. The normal behavior of the sampling distribution is ONLY applicable to sample averages. Here is another example to demonstrate this.</p>
<p>Suppose we want to know the percentage of binge drinkers in college campuses. A good point estimate for this parameter is the sample proportion <span class="math inline">\(\hat p\)</span>. What is the sampling distribution of this statistic <span class="math inline">\(\hat p\)</span>? Let’s create a small simulation to find this out. Here are the steps:</p>
<ul>
<li><p>Create a population of binge and non-binge drinkers</p></li>
<li><p>Draw a sample from this population, say of size <span class="math inline">\(n=30\)</span> and calculate <span class="math inline">\(\hat p\)</span>.</p></li>
<li><p>Repeat the above step (sampling and calculation of <span class="math inline">\(\hat p\)</span>) for a large number of times and plot the distribution of those <span class="math inline">\(\hat p\)</span> values.</p></li>
</ul>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb9-1" data-line-number="1">population_size &lt;-<span class="st"> </span><span class="fl">1E6</span></a>
<a class="sourceLine" id="cb9-2" data-line-number="2">sample_size &lt;-<span class="st"> </span><span class="dv">20</span></a>
<a class="sourceLine" id="cb9-3" data-line-number="3">my_drinking_pop &lt;-<span class="st"> </span><span class="kw">rbinom</span>(population_size, <span class="dv">1</span>, <span class="dt">prob =</span> <span class="fl">0.20</span>)</a>
<a class="sourceLine" id="cb9-4" data-line-number="4"></a>
<a class="sourceLine" id="cb9-5" data-line-number="5">simulated_samples &lt;-<span class="st"> </span><span class="fl">1E3</span></a>
<a class="sourceLine" id="cb9-6" data-line-number="6">phat &lt;-<span class="st"> </span><span class="dv">0</span> <span class="co">#storage bucket</span></a>
<a class="sourceLine" id="cb9-7" data-line-number="7"></a>
<a class="sourceLine" id="cb9-8" data-line-number="8"><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>simulated_samples)</a>
<a class="sourceLine" id="cb9-9" data-line-number="9">{</a>
<a class="sourceLine" id="cb9-10" data-line-number="10">  mysample &lt;-<span class="st"> </span><span class="kw">sample</span>(my_drinking_pop, <span class="dt">size =</span> sample_size)</a>
<a class="sourceLine" id="cb9-11" data-line-number="11">  phat[i] &lt;-<span class="st"> </span><span class="kw">sum</span>(mysample)<span class="op">/</span>sample_size</a>
<a class="sourceLine" id="cb9-12" data-line-number="12">}</a>
<a class="sourceLine" id="cb9-13" data-line-number="13"></a>
<a class="sourceLine" id="cb9-14" data-line-number="14"><span class="kw">ggplot</span>() <span class="op">+</span></a>
<a class="sourceLine" id="cb9-15" data-line-number="15"><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="dt">mapping =</span> <span class="kw">aes</span>(<span class="dt">x =</span> phat),</a>
<a class="sourceLine" id="cb9-16" data-line-number="16">                 <span class="dt">bins =</span> <span class="dv">13</span>) <span class="op">+</span></a>
<a class="sourceLine" id="cb9-17" data-line-number="17"><span class="st">  </span><span class="kw">labs</span>( <span class="dt">title =</span> <span class="st">&#39;Sampling Distribution of phat&#39;</span>,</a>
<a class="sourceLine" id="cb9-18" data-line-number="18">        <span class="dt">subtitle =</span> <span class="st">&#39;Sample size n = 20&#39;</span>,</a>
<a class="sourceLine" id="cb9-19" data-line-number="19">                     <span class="dt">x =</span> <span class="st">&#39;phat&#39;</span>)</a></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<p>As you can see, for <span class="math inline">\(n=20\)</span> the sampling distribution of <span class="math inline">\(\hat p\)</span> is somewhat skewed. We can increase the sample size and see what happens to the sampling distribution.</p>
<p><br />
</p>
<p>The following plots shows relationship of <span class="math inline">\(n\)</span> with the shape and spread of the sampling distribution.</p>
<p><br />
</p>
<p><img src="_main_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
<p><br />
</p>
<p>It seems like the Central Limit Theorem is at play. That is, the sampling distribution of <span class="math inline">\(\hat p\)</span> looks normal for large <span class="math inline">\(n\)</span>. But, we know that the theorem only applies to AVERAGES. Now you might wonder is <span class="math inline">\(\hat p\)</span> an average?</p>
<p>The answer is ‘Yes’. It is a proper average. It does not look like one, but we can show why it is an average. Let’s denote a random sample of binge grinkers as <span class="math inline">\(x_1, x_2, \ldots, x_n\)</span>. Each <span class="math inline">\(x_i\)</span> is either a <span class="math inline">\(1\)</span> or <span class="math inline">\(0\)</span>, depending on whether the person is a binge drinker or not. Now if we write out the formula for the sample proportion <span class="math inline">\(\hat p\)</span> you’ll see why it is an average.</p>
<p><br />
</p>
<p><span class="math display">\[ \begin{array}{ll}
\hat p &amp;= \frac{Number \ of \ binge \ drinkers \ in\  the\ sample}{Total\ number\ of\ people\ in\ the\ sample} \\
&amp;=  \frac{\sum_{i=1}^nx_i}{n}
\end{array}
\]</span></p>
<p>As shown, above, <span class="math inline">\(\hat p\)</span> is an average and that’s why the sampling distribution of <span class="math inline">\(\hat p\)</span> behaves according to the Central Limit Theorem (CLT). It is now time to take stock of the important facts that we observed so far. Consider the following summary table:</p>
<p><br />
</p>
<table>
<thead>
<tr class="header">
<th align="left">Statistic</th>
<th align="center">Obeys CLT</th>
<th align="left">Shape at n = 30</th>
<th align="left">Shape at n = 50</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Sample Mean (<span class="math inline">\(\bar x\)</span>)</td>
<td align="center">Yes</td>
<td align="left">Skewed</td>
<td align="left">Skewed</td>
</tr>
<tr class="even">
<td align="left">Sample Max</td>
<td align="center">No</td>
<td align="left">not relevant</td>
<td align="left">not relevant</td>
</tr>
<tr class="odd">
<td align="left">Sample proportion (<span class="math inline">\(\hat p\)</span>)</td>
<td align="center">Yes</td>
<td align="left">Skewed</td>
<td align="left">Skewed</td>
</tr>
</tbody>
</table>
<p><br />
</p>
<p>Now you probably see why I labeled this chapter as “The infamous n &gt; 30 rule”. Most people believe that we can make use of the CLT if the sample size is “larger than 30”. But, as you saw in the above examples, this “rule” is extremely questionable. You might object to this observation by saying: “Well, you used simulated data. You could have cherry-picked your data to”prove&quot; a point&quot;. Certainly, this is a valid (and reasonable) objection. Let us therefore look into some real datasets.</p>
<p><br />
</p>
</div>
<div id="explorations-with-real-data" class="section level2">
<h2><span class="header-section-number">3.2</span> Explorations with Real Data</h2>
<p>In this section, we will look at 3 examples with real data. Keep in mind, these examples are hard to find. Because, it is very unlikely that we have ALL the members (data) available from a population. If we have have all data points from a population, there is no need for statistical inference. These examples are chosen to highlight one of the main misconceptions of CLT, namely, the ‘<span class="math inline">\(n&gt;30\)</span> rule’ (the title of this chapter!). In each example, when you look at the sampling distributions of the mean, pay close attention to the sample size. Ask yourself, at what sample size does the sampling distributions start to look more like a normal model.</p>
<div id="nba-player-salaries" class="section level3 unnumbered">
<h3>NBA Player Salaries</h3>

<div class="example">
<span id="exm:unnamed-chunk-20" class="example"><strong>Example 3.1  </strong></span>NBA player salaries in 2016 season (Kolby Bryant’s last season). As with any other salary distribution, these values are skewed with few players earning a LOT.
</div>

<p><br />
</p>
<p>The following plots show the population distribution of NBA player salaries in 2016.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-21-1.png" width="672" /></p>
<p><br />
</p>
<p>The following plots show the sampling distributions are made from samples from this <strong>population</strong>.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-22-1.png" width="1152" /><br />
</p>
<p><strong>Observations</strong></p>
<p>The first thing you will notice that at <span class="math inline">\(n=30\)</span>, the skewness is quite visible. At <span class="math inline">\(n=50\)</span>, it is still slightly skewed. So may be we ought to modify the “rule” as <span class="math inline">\(n&gt;50\)</span>?</p>
</div>
<div id="undergraduates-in-us-colleges-and-universities" class="section level3 unnumbered">
<h3>Undergraduates in US Colleges and Universities</h3>
<p>The second example is from ALL US colleges and universities. Note that there are about 5000 colleges and universities in the US. However, there are many missing datapoints since it is hard to find all data from all institutions. As a result the population size is 1269. In this example, we are interested in the undergraduate population in US colleges and universities. Here is the population distribution.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-23-1.png" width="672" /></p>
<p><br />
</p>
<p>The following plots show the sampling distributions are made from random samples from the above <strong>population</strong>.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-24-1.png" width="1152" /></p>
<p><br />
</p>
<p>Even this example, at <span class="math inline">\(n=30\)</span> the skewness is quite visible. At <span class="math inline">\(n=50\)</span> the skewness is still there. Even at <span class="math inline">\(n=100\)</span>, if you look at carefully you’ll see that there is a slight skewness. So may be the rule should be <span class="math inline">\(n&gt;100\)</span>?</p>
</div>
<div id="departure-delays-in-laguardia-airport" class="section level3 unnumbered">
<h3>Departure Delays in LaGuardia Airport</h3>
<p>Now, let’s look at the final example. This data is about flight delays. You can find a lot of information and download data for past years from this website: <a href="https://www.transtats.bts.gov/ONTIME/Departures.aspx" class="uri">https://www.transtats.bts.gov/ONTIME/Departures.aspx</a></p>
<p>The dataset we are looking at consists of ALL flights that departed from LaGuardia airport in 2017 from the three main carriers (American Airlines, Delta, and United). That is, all departures from Jan 1 2017 to Dec 31 2017. The variable of interest is departure delay time. First, let’s take a look at the population distribution of departure delays.</p>
<p><br />
</p>
<p><img src="_main_files/figure-html/unnamed-chunk-25-1.png" width="672" /></p>
<p>Now let’s look at the corresponding sampling distribution for the sample mean.</p>
<p><br />
</p>
<p><img src="_main_files/figure-html/unnamed-chunk-26-1.png" width="1152" /><br />
</p>
<p>You can clearly see that none of the above plots look normally distributed. Let us increase the sample size even further and see at what point it starts to look normal.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-27-1.png" width="1152" /></p>
<p>The above plots underscore the main point of this chapter. The common belief that if <span class="math inline">\(n&gt;30\)</span> the CLT is applicable for sample means. This is a very misguided notion. The above plots demonstrate that for this dataset the sample size <span class="math inline">\(n\)</span> should be around 1000(!) to see a symmetric, bell shaped sampling distribution.</p>
<p>By now, hopefully, you are convinced that there is a problem in the common understanding of the Central Limit Theorem. The main point in this chapter is to be aware of this issue and be very cautious in using the CLT.</p>
<p><br />
Run the following command in RStudio to open the data and do this exploration yourself. It will open an app that allows you to change the sample size and construct sampling distributions on your own.</p>
<p><br />
</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb10-1" data-line-number="1"><span class="kw">library</span>(shiny)</a>
<a class="sourceLine" id="cb10-2" data-line-number="2"><span class="kw">runGitHub</span>(<span class="dt">repo =</span> <span class="st">&quot;gitcnk/Apps/&quot;</span>, <span class="dt">subdir=</span><span class="st">&#39;CLT_NBA&#39;</span>)</a></code></pre></div>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb11-1" data-line-number="1"><span class="kw">library</span>(shiny)</a>
<a class="sourceLine" id="cb11-2" data-line-number="2"><span class="kw">runGitHub</span>(<span class="dt">repo =</span> <span class="st">&quot;gitcnk/Apps/&quot;</span>, <span class="dt">subdir=</span><span class="st">&#39;CLT_Colleges&#39;</span>)</a></code></pre></div>
<p><br />
</p>
</div>
</div>
<div id="some-questions-to-ponder-1" class="section level2">
<h2><span class="header-section-number">3.3</span> Some Questions to Ponder</h2>
<pre><code>1. Why do people advocate for the &quot;n &gt; 30 rule&quot; if it is problematic?</code></pre>
<p><strong>Answer:</strong><br />
Hard to say. My guess is that this is similar to our beliefs and practices of recycling plastics. That is, we were told to toss our plastics into the recycling bin and we normally believe that those plastics will get recycled somehow. But the reality is MUCH more complicated than that. Here is a wonderful documentary about recycling pastics and its realities: <a href="https://www.youtube.com/watch?v=-dk3NOEgX7o" class="uri">https://www.youtube.com/watch?v=-dk3NOEgX7o</a></p>
<p>Similarly, the Central Limit Theorem should be used with caution. There are many factors that we need to look into before we jump in and use this theorem. The issue mainly lies in understanding the population and its distribution. Since we don’t have access to the population (if we did we’ll be all be at the beach!), we have to rely on a random sample to make a judgement about the variability, skewness and outlier in the population. This is a very challenging task. For example, recall the flight delay example. If we haven’t had the entire dataset with us, would we have guessed that the population may look extremely skewed? Would we have guessed that there might be flights that are delayed 20 hours! Consider an example about cancer medication and their survival time. Unless we have an in depth knowledge about the cancer and the drug, it would be very difficult to even have a vague idea about the population distribution. In this case we need to rely on domain experts to tell us more about variance, skewness and extreme values.</p>
<p>In reality we only have a single sample from a given population and we need to make a judgement call on whether CLT is an appropriate technique to use with this sample. That’s why it is better to have a healthy level of skepticism about our data before we proceed. As good statisticians, it is our duty to inform our clients about the limitations of the data and the inferences that we draw from them.</p>
<pre><code>2. What are some of the signs that CLT may be questionble?</code></pre>
<p><strong>Answer:</strong><br />
If you look back the simulated data examples and real data examples you’ll see that, for skewed data, it takes much larger sample size (in some cases in the 100’s) to use the CLT. Also, in the final example with departure delays, the population was not only highly skewed but also contained extremely large values in the tail. This is definitely a red flag. So if you believe that the population is skewed and/or with extreme values you need to be super careful with the CLT.</p>
<pre><code>3. How can we know whether the population is skewed or not when we don&#39;t have access 
to the entire population?</code></pre>
<p><strong>Answer:</strong>
This one is tricky. Yes, we never have access to the entire population. All we have is a single random sample. If our sampling process had done a good job in capturing the variance in the population then it will provide important clues about the skewness and presence of extreme values in the population. For example, here are two random sample of sizes <span class="math inline">\(n=30\)</span> and <span class="math inline">\(n=100\)</span> respectively from the flight delay example.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-30-1.png" width="1152" /></p>
<p><br />
</p>
<p>As you can see from the above two plots, the bigger sample was able able to capture more of the variance in the population but still failed to include some of the really large delay times even with <span class="math inline">\(n=100\)</span>. But, this is where the statisticians need to step in. We can raise a red flag against anyone who is tempted to use the CLT with a sample like this for hypothesis testing or confidence intervals. We can educate them to see the danger of using CLT with a sample like this.</p>
<pre><code>4. If we see extreme values (like in the above two samples) should we remove them 
and proceed to use the CLT?</code></pre>
<p><strong>Answer:</strong> The safe answer is ‘no’. Removing data points has to be done with extreme care. There are some instances where removing extreme values may be legitimate.</p>
<ul>
<li><p>If the data values are recorded incorrectly (errors in the data). For example, someone might have keyed in 10,000 (incorrect) instead of 1000 (correct). If we know for sure that this is the case, first we should try to find the correct value, if not remove it.</p></li>
<li><p>If the purpose of the analysis dictates the removal of extreme values. Can you think of a situation where it might be essential to remove extreme values? This will be a part of your HW for this chapter.</p></li>
</ul>
<!-- From this point on, these are codes I used to generate the data and plots.






 -->

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="sampling-distributions.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="the-bootstrap-method.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
